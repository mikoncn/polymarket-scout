import sys
import requests
import pandas as pd
import time
import os
from dotenv import load_dotenv
from rich.console import Console
from rich.table import Table

# åŠ è½½é…ç½®
load_dotenv()

# å¤„ç† Windows ç³»ç»Ÿä¸­çš„ UTF-8 ç¼–ç é—®é¢˜
# ç§»é™¤æ‰‹åŠ¨é‡å®šå‘ï¼Œäº¤ç»™ rich å¤„ç†


console = Console()

# é…ç½®è½½å…¥ (ä¸»è¦ä» .env åŠ è½½ï¼Œå¦‚æœå­˜åœ¨ SCOUT_AUTO_PRESET åˆ™ä»é¢„è®¾ JSON è¦†ç›–)
MIN_VOLUME = float(os.getenv("SCOUT_MIN_VOLUME", 5000))
MIN_PROB = float(os.getenv("SCOUT_MIN_PROB", 0.15))
MAX_PROB = float(os.getenv("SCOUT_MAX_PROB", 0.85))
FETCH_LIMIT = int(os.getenv("SCOUT_FETCH_LIMIT", 200))
MAX_RUNTIME = int(os.getenv("SCOUT_RUNTIME_LIMIT", 30))
SCOUT_TAG_NAME = os.getenv("SCOUT_TAG", "").strip()
MIN_LIQUIDITY = float(os.getenv("SCOUT_MIN_LIQUIDITY", 0) or 0)
MAX_DAYS_TO_END = int(os.getenv("SCOUT_MAX_DAYS_TO_END", -1) or -1)
SEARCH_KEYWORD = os.getenv("SCOUT_SEARCH", "").strip()
EXCLUDE_KEYWORDS_RAW = os.getenv("SCOUT_EXCLUDE_KEYWORDS", "")
ORDER_BY = os.getenv("SCOUT_ORDER_BY", "volume").strip().lower()

# [Automation] é»˜è®¤ä»»åŠ¡é¢„è®¾è¦†ç›–é€»è¾‘
AUTO_PRESET = os.getenv("SCOUT_AUTO_PRESET", "").strip().replace("'", "").replace('"', '')
if AUTO_PRESET:
    import json
    preset_path = os.path.join("presets", f"{AUTO_PRESET}.json")
    if os.path.exists(preset_path):
        console.print(f"[bold cyan][Mikon AI][/bold cyan] ğŸ¤– è‡ªåŠ¨åŒ–æ¨¡å¼å¯åŠ¨: [yellow]{AUTO_PRESET}[/yellow]")
        try:
            with open(preset_path, 'r', encoding='utf-8') as f:
                preset_data = json.load(f)
                if "SCOUT_MIN_VOLUME" in preset_data: MIN_VOLUME = float(preset_data["SCOUT_MIN_VOLUME"] or 0)
                if "SCOUT_MIN_PROB" in preset_data: MIN_PROB = float(preset_data["SCOUT_MIN_PROB"] or 0)
                if "SCOUT_MAX_PROB" in preset_data: MAX_PROB = float(preset_data["SCOUT_MAX_PROB"] or 1)
                if "SCOUT_TAG" in preset_data: SCOUT_TAG_NAME = str(preset_data["SCOUT_TAG"] or "").strip()
                if "SCOUT_MIN_LIQUIDITY" in preset_data: MIN_LIQUIDITY = float(preset_data["SCOUT_MIN_LIQUIDITY"] or 0)
                if "SCOUT_MAX_DAYS_TO_END" in preset_data: MAX_DAYS_TO_END = int(preset_data.get("SCOUT_MAX_DAYS_TO_END") or -1)
                if "SCOUT_SEARCH" in preset_data: SEARCH_KEYWORD = str(preset_data["SCOUT_SEARCH"] or "").strip()
                if "SCOUT_EXCLUDE_KEYWORDS" in preset_data: EXCLUDE_KEYWORDS_RAW = str(preset_data["SCOUT_EXCLUDE_KEYWORDS"] or "")
                if "SCOUT_ORDER_BY" in preset_data: ORDER_BY = str(preset_data["SCOUT_ORDER_BY"] or "volume").strip().lower()
                if "SCOUT_FETCH_LIMIT" in preset_data: FETCH_LIMIT = int(preset_data["SCOUT_FETCH_LIMIT"] or 200)
                if "SCOUT_RUNTIME_LIMIT" in preset_data: MAX_RUNTIME = int(preset_data["SCOUT_RUNTIME_LIMIT"] or 30)
                console.print(f"[green]âœ… å·²åŒæ­¥ [bold]{AUTO_PRESET}[/bold] çš„æ‰€æœ‰ä½œæˆ˜æŒ‡ä»¤ã€‚[/green]\n")
        except Exception as e:
            console.print(f"[red]âŒ é¢„è®¾åŠ è½½å¤±è´¥: {e}[/red]")

# åå¤„ç†
EXCLUDE_KEYWORDS = [k.strip().lower() for k in EXCLUDE_KEYWORDS_RAW.split(',') if k.strip()]

def get_tag_id(tag_name):
    """æ ¹æ®å“ç±»åç§°æ™ºèƒ½åŒ¹é… Tag ID"""
    if not tag_name:
        return None, None
        
    # [Feature] å¦‚æœè¾“å…¥çš„æ˜¯çº¯æ•°å­—ï¼Œç›´æ¥å½“åš ID ä½¿ç”¨
    if str(tag_name).isdigit():
        return str(tag_name), f"Tag-{tag_name}"

    try:
        # å°è¯•æœç´¢åŒ¹é…çš„æ ‡ç­¾ (æ‰©å¤§æœç´¢èŒƒå›´å¹¶ä¼˜å…ˆç²¾ç¡®åŒ¹é…)
        url = f"https://gamma-api.polymarket.com/tags?limit=5000"
        resp = requests.get(url, timeout=5)
        tags = resp.json()
        
        # ç¬¬ä¸€è½®ï¼šå¯»æ‰¾ç²¾ç¡®åŒ¹é…
        for t in tags:
            label = t.get('label', '')
            if tag_name.lower() == label.lower():
                return t.get('id'), t.get('label')
        
        # ç¬¬äºŒè½®ï¼šæ¨¡ç³ŠåŒ¹é…
        for t in tags:
            label = t.get('label', '').lower()
            if tag_name.lower() in label:
                return t.get('id'), t.get('label')
    except:
        pass
    return None, None

def scout():
    start_t = time.time()
    console.print(f"\n[bold cyan][Mikon AI Army][/bold cyan] é—ªç”µä¾¦å¯Ÿå¯åŠ¨ ({MAX_RUNTIME}s å€’è®¡æ—¶)...")
    
    tag_id, actual_label = get_tag_id(SCOUT_TAG_NAME)
    if SCOUT_TAG_NAME and not tag_id:
        console.print(f"[yellow]âš ï¸ æœªæ‰¾åˆ°å“ç±» '{SCOUT_TAG_NAME}'ï¼Œå°†æ‰§è¡Œå…¨å±€æ‰«æã€‚[/yellow]")
        tag_info = " | å“ç±»: å…¨å±€"
    elif tag_id:
        tag_info = f" | å“ç±»: {actual_label} (ID: {tag_id})"
    tag_info = f" | å“ç±»: {actual_label} (ID: {tag_id})" if tag_id else " | å“ç±»: å…¨å±€"
        
    console.print(f"[dim]å½“å‰é…ç½®è§„åˆ™: æˆäº¤é‡ > ${MIN_VOLUME:,.0f} | èƒœç‡ {MIN_PROB:.0%} - {MAX_PROB:.0%}{tag_info}[/dim]")
    if MAX_DAYS_TO_END >= 0:
        console.print(f"[dim yellow]â³ å€’è®¡æ—¶è¿‡æ»¤: ä»…æ˜¾ç¤º {MAX_DAYS_TO_END} å¤©å†…ç»“ç›˜çš„å¸‚åœº[/dim yellow]")
    console.print("")
    
    # åˆå§‹åŒ–å˜é‡
    final_data = []
    error_msg = None

    with console.status("[bold green]æ­£åœ¨çªè¢­ Polymarket æ•°æ®ä¸­å¿ƒ...", spinner="earth"):
        try:
            # 1. åˆ†é¡µè·å–æ´»è·ƒå¸‚åœº (ç»•è¿‡å•æ¬¡ 500 æ¡é™åˆ¶)
            all_markets = []
            offset = 0
            
            # è¯»å–æ’åºé…ç½®
            ORDER_BY = os.getenv("SCOUT_ORDER_BY", "volume")
            
            # æ˜ å°„æ’åºå‚æ•°
            sort_param = ""
            if ORDER_BY == "liquidity":
                sort_param = "&order=liquidity&ascending=false"
            elif ORDER_BY == "endDate":
                # æŒ‰ç”±äºç»“æŸæ—¥æœŸæ’åº (å³å°†è¿‡æœŸçš„æ’å‰é¢)
                sort_param = "&order=endDate&ascending=true" 
            else:
                # é»˜è®¤æŒ‰ Volume é™åº
                sort_param = "&order=volume&ascending=false"

            # æ„é€ åŸºç¡€ URL å‚æ•°
            base_params = f"active=true&closed=false{sort_param}"
            tag_param = f"&tag_id={tag_id}" if tag_id else ""
            
            # [æ ¸å¿ƒä¼˜åŒ–] ä½¿ç”¨ Server-Side è¿‡æ»¤ç»“æŸæ—¥æœŸ (å¦‚æœä½ æƒ³è¦æ—¥ç»“ï¼Œå°±åªæ‹‰å–æ—¥ç»“çš„æ•°æ®!)
            date_filter_param = ""
            if MAX_DAYS_TO_END >= 0:
                # è®¡ç®—æˆªæ­¢æ—¥æœŸ (å½“å‰æ—¶é—´ + MAX_DAYS)
                # ä½¿ç”¨ datetime to ISO format
                import datetime
                # æ³¨æ„: API éœ€è¦ UTC æ—¶é—´æ ¼å¼ ISO
                future_date = datetime.datetime.now(datetime.timezone.utc) + datetime.timedelta(days=MAX_DAYS_TO_END + 1)
                date_str = future_date.isoformat().replace("+00:00", "Z") # å…¼å®¹æ€§è°ƒæ•´
                date_filter_param = f"&end_date_max={date_str}"
                console.print(f"[dim cyan]ğŸš€ å¯ç”¨æœåŠ¡ç«¯æé€Ÿè¿‡æ»¤: end_date_max={date_str}[/dim cyan]")

            
            # å¦‚æœ FETCH_LIMIT ä¸º 1000ï¼Œéœ€è¦å¾ªç¯ offset=0, offset=500
            while len(all_markets) < FETCH_LIMIT:
                # å‰©ä½™éœ€è¦è·å–çš„æ•°é‡
                remaining = FETCH_LIMIT - len(all_markets)
                # å•æ¬¡æœ€å¤§ 500 (Gamma API é™åˆ¶)
                batch_limit = min(500, remaining)
                
                url = f"https://gamma-api.polymarket.com/markets?{base_params}&limit={batch_limit}&offset={offset}{tag_param}{date_filter_param}"
                
                # å¢åŠ  User-Agent ä¼ªè£…å’Œè¶…æ—¶æ—¶é—´
                headers = {
                    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
                }
                
                # console.print(f"DEBUG: Fetching offset {offset}...") 
                resp = requests.get(url, headers=headers, timeout=30)
                batch_data = resp.json()
                
                # API ç»“æ„æ ¡éªŒä¸å®¹é”™
                if not isinstance(batch_data, list):
                    if isinstance(batch_data, dict) and 'data' in batch_data:
                        batch_data = batch_data['data']
                    else:
                        batch_data = []
                
                if not batch_data:
                    break # æ²¡æœ‰æ›´å¤šæ•°æ®äº†
                    
                all_markets.extend(batch_data)
                offset += len(batch_data)
                
                # é¿å…è¿‡å¿«è¯·æ±‚
                time.sleep(0.2)
            
            # ä½¿ç”¨æ‰€æœ‰è·å–åˆ°çš„å¸‚åœºè¿›è¡Œè¿‡æ»¤
            markets = all_markets
            
            # [URL å»é‡] ç”¨äºè®°å½•å·²å¤„ç†çš„é“¾æ¥
            seen_urls = set()

            for m in markets:
                # 30ç§’ç¡¬é™åˆ¶ä¿æŠ¤ -> æ”¾å®½åˆ° 60s
                if time.time() - start_t > MAX_RUNTIME:
                     error_msg = f"å·²è¾¾åˆ°æœ€å¤§è¿è¡Œæ—¶é—´ ({MAX_RUNTIME}s)ï¼Œæå‰è¿”å›éƒ¨åˆ†ç»“æœ"
                     break
                     
                title = m.get('question', m.get('title', 'Unknown'))
                slug = m.get('slug', '') # market slug
                
                # æ„é€ é“¾æ¥ç”¨äºå»é‡æ£€æŸ¥
                # API é€šå¸¸è¿”å› market_slugï¼Œé“¾æ¥æ˜¯ polymarket.com/market/{slug}
                # æˆ–è€… event_slug?
                # ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬ç”¨ç”Ÿæˆçš„ full_url å»é‡
                market_slug = m.get('slug', '')
                event_slug = m.get('event_slug', '') # æœ‰äº›æœ‰ event_slug
                
                # ä¼˜å…ˆä½¿ç”¨ event_slug å¦‚æœå­˜åœ¨ (å› ä¸ºå¤šä¸ª market å¯èƒ½å±äºåŒä¸€ä¸ª event)
                # ä½†ç”¨æˆ·è¯´ "é“¾æ¥ä¸€æ ·"ï¼Œé€šå¸¸æ˜¯ event page
                # æˆ‘ä»¬å…ˆç”Ÿæˆ urlï¼Œå† check
                
                # æ„å»º URL (Gamma API è¿”å› slug)
                url = f"https://polymarket.com/market/{market_slug}"
                
                # å¦‚æœè¿™ä¸ª URL å·²ç»å‡ºç°è¿‡ï¼Œç›´æ¥è·³è¿‡ (ç”¨æˆ·è¦æ±‚: generate one record)
                if url in seen_urls:
                    continue
                
                seen_urls.add(url)
                
                desc = m.get('description', '')
                vol = float(m.get('volume', 0))
                slug = m.get('market_slug', m.get('slug', ''))
                
                # ... (åç»­å¤„ç†ä¿æŒä¸å˜)
                # æ„é€ è¿æ¥
                link = f"https://polymarket.com/market/{slug}" if slug else "N/A"
                
                if m.get('closed') is True or m.get('resolved') is True:
                    continue

                # ä»·æ ¼ä¿¡æ¯æ¢é’ˆ
                prices = m.get('outcomePrices', [])
                if isinstance(prices, str):
                    try:
                        import json
                        prices = json.loads(prices)
                    except:
                        prices = []
                
                if not prices:
                    prices = [t.get('price') for t in m.get('tokens', []) if t.get('price') is not None]
                
                if not prices:
                    continue
                
                prob = float(prices[0]) if prices[0] is not None else 0.5
                
                # è¿‡æ»¤æå…¶æ¥è¿‘ç»“ç›˜çš„å¸‚åœº (èƒœç‡ > 99% æˆ– < 1% è§†ä¸ºæ— æ•ˆ)
                if prob > 0.99 or prob < 0.01:
                    continue
                
                # æå–æµåŠ¨æ€§å’Œç»“æŸæ—¥æœŸ
                liquidity = float(m.get('liquidity', 0))
                end_date_str = m.get('endDate', '')
                
                # é«˜çº§è¿‡æ»¤æ¡ä»¶ (å¯é€‰)
                # 1. æµåŠ¨æ€§è¿‡æ»¤
                if MIN_LIQUIDITY > 0 and liquidity < MIN_LIQUIDITY:
                    continue
                
                # 2. ç»“æŸæ—¥æœŸå€’è®¡æ—¶è¿‡æ»¤
                days_to_end = None
                
                # å¦‚æœå¼€å¯äº†å€’è®¡æ—¶è¿‡æ»¤ (>=0)ï¼Œåˆ™å¿…é¡»æœ‰æœ‰æ•ˆçš„ç»“æŸæ—¥æœŸ
                if MAX_DAYS_TO_END >= 0 and not end_date_str:
                    continue

                if end_date_str:
                    try:
                        # ä½¿ç”¨ pandas è¿›è¡Œæ›´ç¨³å¥çš„æ—¥æœŸè§£æ
                        end_date = pd.to_datetime(end_date_str)
                        if end_date.tzinfo is None:
                            end_date = end_date.tz_localize('UTC')
                        
                        now = pd.Timestamp.now(tz='UTC')
                        delta = end_date - now
                        days_to_end = delta.days
                        
                        # Only apply filter if enabled (>=0)
                        if MAX_DAYS_TO_END >= 0:
                            # ä¸¥æ ¼è¿‡æ»¤: å¿…é¡»åœ¨ [0, MAX] èŒƒå›´å†… (è´Ÿæ•°è¡¨ç¤ºå·²è¿‡æœŸä½†æœªç»“ç®—ï¼Œé€šå¸¸æ’é™¤ï¼Œæˆ–éœ€ç”¨æˆ·æŒ‡å®š)
                            # è¿™é‡Œä¿æŒ < 0 ä¹Ÿæ’é™¤ï¼Œå› ä¸ºæˆ‘ä»¬è¦æ‰¾æœªæ¥çš„. 
                            # ä¿®æ­£: days_to_end=0 means < 24h. 
                            if days_to_end < 0 or days_to_end > MAX_DAYS_TO_END:
                                continue
                    except Exception as e:
                        # æ—¥æœŸè§£æå¤±è´¥ï¼Œå¦‚æœå¼€å¯äº†ä¸¥æ ¼è¿‡æ»¤ï¼Œåˆ™æ’é™¤
                        if MAX_DAYS_TO_END >= 0:
                            continue
                        pass
                
                # 3. å…³é”®è¯æœç´¢è¿‡æ»¤ (æ”¯æŒé€—å·åˆ†éš”çš„ OR é€»è¾‘)
                if SEARCH_KEYWORD:
                    keywords = [k.strip().lower() for k in SEARCH_KEYWORD.split(',') if k.strip()]
                    title_lower = str(title).lower()
                    if keywords:
                        match_found = False
                        for kw in keywords:
                            if kw in title_lower:
                                match_found = True
                                break
                        if not match_found:
                            continue
                
                # 4. æ’é™¤å…³é”®è¯é»‘åå•
                if EXCLUDE_KEYWORDS:
                    is_excluded = False
                    for kw in EXCLUDE_KEYWORDS:
                        if kw in str(title).lower():
                            is_excluded = True
                            break
                    if is_excluded:
                        continue

                final_data.append({
                    "Title": str(title),
                    "Volume": vol,
                    "Prob": prob,
                    "Liquidity": liquidity,
                    "DaysToEnd": days_to_end if days_to_end is not None else 999,
                    "Link": link
                })
        except Exception as e:
            error_msg = str(e)
            console.print(f"[dim red]æ¢æµ‹å¼‚å¸¸: {e}[/dim red]")
            pass

    # å…œåº•ï¼šå¦‚æœ API å¼‚å¸¸å¯¼è‡´æ— æ•°æ®ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
    if not final_data:
        if error_msg:
             console.print(f"[yellow]è­¦å‘Š: API è¯·æ±‚å¤±è´¥ ({error_msg})[/yellow]")
             final_data = [{
                "Title": f"âš ï¸ é”™è¯¯: API è¿æ¥å¤±è´¥ - {error_msg}", 
                "Volume": 0, "Prob": 0.5, "Liquidity": 0, "DaysToEnd": 0, "Link": "N/A"
             }]
        else:
             # å¦‚æœæ²¡æœ‰æŠ¥é”™ä½†è¿‡æ»¤å®Œäº†ï¼Œæ˜¾ç¤ºç©ºæç¤º
             final_data = []

    # æŒ‰é…ç½®çš„æ’åºç­–ç•¥æ’åº
    sort_key_map = {
        'volume': lambda x: x['Volume'],
        'liquidity': lambda x: x.get('Liquidity', 0),
        'enddate': lambda x: x.get('DaysToEnd', 999999),
        'prob': lambda x: abs(x['Prob'] - 0.5)  # æç«¯å€¼ä¼˜å…ˆ
    }
    
    sort_key = sort_key_map.get(ORDER_BY, sort_key_map['volume'])
    sorted_data = sorted(final_data, key=sort_key, reverse=True)
    
    # åº”ç”¨ Vibe Filter (è‡ªå®šä¹‰æˆ–é»˜è®¤èƒœç‡åŒºé—´)
    vibe_list = [r for r in sorted_data if r['Volume'] > MIN_VOLUME and MIN_PROB <= r['Prob'] <= MAX_PROB]
    
    # ç»Ÿè®¡è¢«èƒœç‡/æˆäº¤é‡è¿‡æ»¤æ‰çš„æ•°é‡ (ç”¨äºè¯Šæ–­)
    filtered_count = len(sorted_data) - len(vibe_list)
    
    display_list = []
    header = ""
    if vibe_list:
        # æ”¾å®½å±•ç¤ºæ•°é‡åˆ°å‰ 50 æ¡
        display_list = vibe_list[:50]
        header = f"ğŸ’ æ ¸å¿ƒä¾¦å¯Ÿç»“æœ (æŸ¥è· {len(vibe_list)} ä¸ªä¼˜è´¨å¸‚åœº)"
    else:
        display_list = sorted_data[:20]
        header = "ğŸ“¡ å…¨å±€å¿«ç…§ (ä»…å±•ç¤ºé«˜æˆäº¤é‡)"
        console.print(f"[dim]æç¤ºï¼šç›®å‰æ— å¸‚åœºç¬¦åˆ {MIN_PROB:.0%}-{MAX_PROB:.0%} èƒœç‡è§„åˆ™ï¼Œå·²è¾“å‡ºå½“å‰æˆäº¤é‡æœ€é«˜çš„æ•°æ®ã€‚[/dim]")

    if filtered_count > 0 and MAX_DAYS_TO_END >= 0:
         console.print(f"[dim yellow]âš ï¸ æ³¨æ„: æœ‰ {filtered_count} ä¸ªç¬¦åˆæ—¥æœŸä½†è¢«èƒœç‡/æˆäº¤é‡è¿‡æ»¤çš„å¸‚åœºã€‚å¦‚ç»“æœè¿‡å°‘ï¼Œè¯·æ”¾å®½èƒœç‡åŒºé—´ã€‚[/dim yellow]")

    # ç»˜åˆ¶ Rich è¡¨æ ¼
    table = Table(title=f"{header}", border_style="cyan", header_style="bold magenta")
    table.add_column("ä¾¦å¯Ÿç›®æ ‡ (Market)", style="white")
    table.add_column("â³ å‰©", justify="right", style="yellow")
    table.add_column("èƒœç‡", justify="center", style="green")
    table.add_column("æˆäº¤é‡", justify="right", style="blue")
    table.add_column("æŸ¥çœ‹é“¾æ¥ (Link)", justify="left", style="underline cyan")

    for r in display_list:
        days_str = str(r['DaysToEnd']) if r['DaysToEnd'] < 900 else ">2y"
        table.add_row(
            r['Title'][:50],
            days_str + "d",
            f"{r['Prob']:.1%}",
            f"${r['Volume']:,.0f}",
            r['Link']
        )

    console.print(table)
    
    # æŒä¹…åŒ–å­˜å‚¨
    try:
        with open("markets_list.txt", "w", encoding="utf-8") as f:
            f.write(f"=== Mikon AI Scout ä¾¦å¯Ÿå®Œæ•´åå• ({pd.Timestamp.now()}) ===\n")
            f.write(f"å…±è®¡æ”¶å½•: {len(display_list)} æ¡è®°å½•\n\n")
            for i, r in enumerate(display_list, 1):
                f.write(f"{i}. ã€{r['Prob']:.1%}ã€‘{r['Title']}\n")
                f.write(f"   æˆäº¤é‡: ${r['Volume']:,.0f}\n")
                f.write(f"   æŸ¥çœ‹é“¾æ¥: {r['Link']}\n")
                f.write("-" * 50 + "\n")
        console.print(f"\n[bold green]ğŸ’¾ å®Œæ•´åå•ï¼ˆå«é“¾æ¥ï¼‰å·²å­˜è‡³: markets_list.txt[/bold green]")
    except Exception as e:
        console.print(f"[red]ä¿å­˜å¤±è´¥: {e}[/red]")

    console.print(f"\n[bold green]âœ… ä¾¦å¯Ÿä»»åŠ¡å®Œæˆã€‚æ€»è€—æ—¶: {time.time()-start_t:.1f}s[/bold green]")

    # [Automation] Webhook æ¨é€é€»è¾‘
    WEBHOOK_URL = os.getenv("SCOUT_WEBHOOK_URL", "").strip()
    if WEBHOOK_URL and display_list:
        try:
            console.print(f"\n[cyan]æ­£åœ¨å‘ Webhook æ¨é€ {len(display_list)} æ¡æƒ…æŠ¥...[/cyan]")
            
            # æ„é€ æ¶ˆæ¯å†…å®¹
            msg_content = f"ğŸ•µï¸ **Mikon Scout ä¾¦å¯ŸæŠ¥å‘Š**\n"
            msg_content += f"ğŸ¯ ç›®æ ‡: {tag_info}\n"
            msg_content += f"ğŸ“Š è§„åˆ™: >${MIN_VOLUME:,.0f} | Win {MIN_PROB:.0%}-{MAX_PROB:.0%}\n"
            msg_content += f"â±ï¸ è€—æ—¶: {time.time()-start_t:.1f}s | æŸ¥è·: {len(display_list)} æ¡\n\n"
            
            for i, r in enumerate(display_list[:10], 1): # é™åˆ¶æ¨é€å‰10æ¡ä»¥å…åˆ·å±
                msg_content += f"{i}. [{r['Prob']:.1%}] **{r['Title']}**\n"
                msg_content += f"   ğŸ’° ${r['Volume']:,.0f} | ğŸ”— <{r['Link']}>\n"
            
            if len(display_list) > 10:
                msg_content += f"\n...è¿˜æœ‰ {len(display_list)-10} æ¡è§å®Œæ•´åå•ã€‚"

            payload = {
                "content": msg_content,
                "username": "Mikon Scout Army"
            }
            
            # å‘é€
            requests.post(WEBHOOK_URL, json=payload, timeout=10)
            console.print("[bold green]âœ… æ¨é€æˆåŠŸï¼[/bold green]")
        except Exception as e:
            console.print(f"[red]âŒ æ¨é€å¤±è´¥: {e}[/red]")

if __name__ == "__main__":
    scout()
